DEFAULT_TEST_GQA_VARIANT = dict(
    GQA_Q_A=dict(
        filename=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_all_questions.jsonl',
        image_folder='/datasets/GQA/images',
        scene_graph_file=None,
        scene_graph_index=None,
        template_file=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA.json',
        type='GQADataset',
        version='q-a'),
    GQA_Q_A_BALANCED=dict(
        filename=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_balanced_questions.jsonl',
        image_folder='/datasets/GQA/images',
        scene_graph_file=None,
        scene_graph_index=None,
        template_file=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA.json',
        type='GQADataset',
        version='q-a'),
    GQA_Q_BC=dict(
        filename=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_all_questions.jsonl',
        image_folder='/datasets/GQA/images',
        scene_graph_file=None,
        scene_graph_index=None,
        template_file=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_BCoT.json',
        type='GQADataset',
        version='q-a'),
    GQA_Q_BC_BALANCED=dict(
        filename=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_balanced_questions.jsonl',
        image_folder='/datasets/GQA/images',
        scene_graph_file=None,
        scene_graph_index=None,
        template_file=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_BCoT.json',
        type='GQADataset',
        version='q-a'),
    GQA_Q_C=dict(
        filename=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_all_questions.jsonl',
        image_folder='/datasets/GQA/images',
        scene_graph_file=None,
        scene_graph_index=None,
        template_file=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_CoT.json',
        type='GQADataset',
        version='q-a'),
    GQA_Q_C_BALANCED=dict(
        filename=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_balanced_questions.jsonl',
        image_folder='/datasets/GQA/images',
        scene_graph_file=None,
        scene_graph_index=None,
        template_file=
        '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_CoT.json',
        type='GQADataset',
        version='q-a'))
GQA_TEST_COMMON_CFG = dict(
    image_folder='/datasets/GQA/images',
    scene_graph_file=None,
    scene_graph_index=None,
    type='GQADataset')
data_args = dict(
    collator_kwargs=dict(max_length=1024, padding=True),
    compute_metric=None,
    gen_kwargs=dict(max_new_tokens=1024, num_beams=1),
    multitest=dict(
        GQA_Q_A=dict(
            cfg=dict(
                filename=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_all_questions.jsonl',
                image_folder='/datasets/GQA/images',
                scene_graph_file=None,
                scene_graph_index=None,
                template_file=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA.json',
                type='GQADataset',
                version='q-a'),
            compute_metric=dict(type='GQAComputeMetrics')),
        GQA_Q_A_BALANCED=dict(
            cfg=dict(
                filename=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_balanced_questions.jsonl',
                image_folder='/datasets/GQA/images',
                scene_graph_file=None,
                scene_graph_index=None,
                template_file=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA.json',
                type='GQADataset',
                version='q-a'),
            compute_metric=dict(type='GQAComputeMetrics')),
        GQA_Q_BC=dict(
            cfg=dict(
                filename=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_all_questions.jsonl',
                image_folder='/datasets/GQA/images',
                scene_graph_file=None,
                scene_graph_index=None,
                template_file=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_BCoT.json',
                type='GQADataset',
                version='q-a'),
            compute_metric=dict(type='GQAComputeMetrics')),
        GQA_Q_BC_BALANCED=dict(
            cfg=dict(
                filename=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_balanced_questions.jsonl',
                image_folder='/datasets/GQA/images',
                scene_graph_file=None,
                scene_graph_index=None,
                template_file=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_BCoT.json',
                type='GQADataset',
                version='q-a'),
            compute_metric=dict(type='GQAComputeMetrics')),
        GQA_Q_C=dict(
            cfg=dict(
                filename=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_all_questions.jsonl',
                image_folder='/datasets/GQA/images',
                scene_graph_file=None,
                scene_graph_index=None,
                template_file=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_CoT.json',
                type='GQADataset',
                version='q-a'),
            compute_metric=dict(type='GQAComputeMetrics')),
        GQA_Q_C_BALANCED=dict(
            cfg=dict(
                filename=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/../../../data/gqa_balanced_questions.jsonl',
                image_folder='/datasets/GQA/images',
                scene_graph_file=None,
                scene_graph_index=None,
                template_file=
                '/lustre/fs1/home/cap6412.student20/git/shikra_eval/config/_base_/dataset/template/VQA_CoT.json',
                type='GQADataset',
                version='q-a'),
            compute_metric=dict(type='GQAComputeMetrics'))),
    test=None,
    train=None,
    validation=None)
model_args = dict(
    cache_dir=None,
    conv_args=dict(
        conv_template='vicuna_v1.1',
        tokenize_kwargs=dict(truncation_size=2048),
        transforms=dict(type='Expand2square')),
    freeze_backbone=False,
    freeze_mm_mlp_adapter=False,
    gen_kwargs_set_bos_token_id=True,
    gen_kwargs_set_eos_token_id=True,
    gen_kwargs_set_pad_token_id=True,
    image_token_len=256,
    mm_use_im_start_end=True,
    mm_vision_select_layer=-2,
    model_max_length=2048,
    model_name_or_path='shikra-7b',
    pretrain_mm_mlp_adapter=None,
    process_func_args=dict(
        conv=dict(type='ShikraConvProcess'),
        image=dict(type='ShikraImageProcessor'),
        target=dict(type='BoxFormatProcess'),
        text=dict(type='ShikraTextProcess')),
    sep_image_conv_front=False,
    target_processor=dict(boxes=dict(type='PlainBoxFormatter')),
    tune_mm_mlp_adapter=False,
    type='shikra',
    version='v1',
    vision_tower='openai/clip-vit-large-patch14')
training_args = dict(
    bf16=False,
    bf16_full_eval=False,
    do_eval=False,
    do_multi_predict=True,
    do_predict=False,
    do_train=False,
    fp16=True,
    fp16_full_eval=True,
    logging_steps=1,
    output_dir='./exp/shikra_eval_gqa',
    overwrite_output_dir=False,
    per_device_eval_batch_size=8,
    predict_with_generate=True,
    remove_unused_columns=False,
    report_to='none',
    seed=42)
